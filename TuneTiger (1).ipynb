{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "JHHHo1dzeYli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ls -s /content/gdrive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91APu4Xyd9-u",
        "outputId": "9a835158-0c85-43bc-e6d7-6ddd4b91fdfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n",
            "Mounted at /content/gdrive\n",
            "total 445624\n",
            "231385  aaa_weights.zip\n",
            " 32814  adapter_model.bin\n",
            "     1 'Ai-skriven uppsats om arbetslöshet.gdoc'\n",
            "     4  annat\n",
            "     0  beedata\n",
            "     4 'Colab Notebooks'\n",
            "     4  convmodel\n",
            "     4  data\n",
            "     1 'Datatekniskt projekt.gdoc'\n",
            "     4 'Datateknisktprojekt grupp 8'\n",
            "     4  densemodel\n",
            "     1  images.txt\n",
            " 16099 'Introduktion KOLL 2022.zip'\n",
            " 11869  JirarnFårEjÖppna.zip\n",
            "     1 'kandidatförslag Factory building - a gamification of functional decomp.gdoc'\n",
            "     1 'Kandidatförslag Självstyrande robot med machine vision.gdoc'\n",
            "    18  keras_metadata.pb\n",
            "  1176 'Kopia av Assignment 7.ipynb'\n",
            "     1 'Kopia av Module4Group68.gdoc'\n",
            " 14102  lab-2-1.zip\n",
            "     1 'labbrapport dd.gdoc'\n",
            "     1 'Maskinorienterad lösningsdokument.gdoc'\n",
            "     1 'minecraft mod checklist.gdoc'\n",
            "     1 'My Drive'\n",
            "     1 'Namnlös presentation.gslides'\n",
            "     1 'Namnlöst dokument (1).gdoc'\n",
            "     1 'Namnlöst dokument.gdoc'\n",
            "     1 'Namnlöst kalkylark (1).gsheet'\n",
            "     1 'Namnlöst kalkylark.gsheet'\n",
            "     1  Nedladdningschecklist.gdoc\n",
            "     1 'Opponering på grupp 7 .gdoc'\n",
            "     1 'pokemon kort! :).gdoc'\n",
            "     1  Report_NS.gdoc\n",
            "     1 'Report_Philosophers (1).gdoc'\n",
            "     1  Report_Philosophers.gdoc\n",
            "   123  saved_model.pb\n",
            "     1 'Sjukintyg Johan Jiremalm.gdoc'\n",
            "    66 'Skiftschema 2023 .xlsx'\n",
            "     4  Skola\n",
            "108390  T1_5L_1_cut1.mp4\n",
            "   489  tokenizer.model\n",
            "    12  Untitled0.ipynb\n",
            "     1  Vattning.gdoc\n",
            " 28509  VID_20220719_112828.mp4\n",
            "   537  video-1647124317.mp4\n",
            "     0  yolov4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/')\n",
        "!pwd\n",
        "!mkdir data\n",
        "!cp gdrive/MyDrive/data/train.csv data\n",
        "!ls\n",
        "!ls data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdGzjtA5d_gq",
        "outputId": "7c6fd848-a26c-4538-8c83-b6ec42d580c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "data  gdrive  sample_data\n",
            "train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nol6G1YM9Uw7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1e351239-c6f7-447a-e4bd-c336c83c4d6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autotrain-advanced\n",
            "  Downloading autotrain_advanced-0.6.37-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.4/130.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: albumentations==1.3.1 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (1.3.1)\n",
            "Collecting codecarbon==2.2.3 (from autotrain-advanced)\n",
            "  Downloading codecarbon-2.2.3-py3-none-any.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/174.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets[vision]~=2.14.0 (from autotrain-advanced)\n",
            "  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate==0.3.0 (from autotrain-advanced)\n",
            "  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipadic==1.0.0 (from autotrain-advanced)\n",
            "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jiwer==3.0.2 (from autotrain-advanced)\n",
            "  Downloading jiwer-3.0.2-py3-none-any.whl (21 kB)\n",
            "Collecting joblib==1.3.1 (from autotrain-advanced)\n",
            "  Downloading joblib-1.3.1-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting loguru==0.7.0 (from autotrain-advanced)\n",
            "  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (1.5.3)\n",
            "Collecting optuna==3.3.0 (from autotrain-advanced)\n",
            "  Downloading optuna-3.3.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.2/404.2 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow==10.0.0 (from autotrain-advanced)\n",
            "  Downloading Pillow-10.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf==4.23.4 (from autotrain-advanced)\n",
            "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic==1.10.11 (from autotrain-advanced)\n",
            "  Downloading pydantic-1.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses==0.0.53 (from autotrain-advanced)\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scikit-learn==1.3.0 (from autotrain-advanced)\n",
            "  Downloading scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m123.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece==0.1.99 (from autotrain-advanced)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.65.0 (from autotrain-advanced)\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting werkzeug==2.3.6 (from autotrain-advanced)\n",
            "  Downloading Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xgboost==1.7.6 (from autotrain-advanced)\n",
            "  Downloading xgboost-1.7.6-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.16.4 (from autotrain-advanced)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (2.31.0)\n",
            "Collecting gradio==3.41.0 (from autotrain-advanced)\n",
            "  Downloading gradio-3.41.0-py3-none-any.whl (20.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops==0.6.1 (from autotrain-advanced)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting invisible-watermark==0.2.0 (from autotrain-advanced)\n",
            "  Downloading invisible_watermark-0.2.0-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging==23.1 (from autotrain-advanced)\n",
            "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (2.13.0)\n",
            "Collecting peft (from autotrain-advanced)\n",
            "  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trl (from autotrain-advanced)\n",
            "  Downloading trl-0.7.2-py3-none-any.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.0/124.0 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken (from autotrain-advanced)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers (from autotrain-advanced)\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate (from autotrain-advanced)\n",
            "  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diffusers==0.21.4 (from autotrain-advanced)\n",
            "  Downloading diffusers-0.21.4-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes (from autotrain-advanced)\n",
            "  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced) (1.11.3)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced) (6.0.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1->autotrain-advanced) (4.8.1.78)\n",
            "Collecting arrow (from codecarbon==2.2.3->autotrain-advanced)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynvml (from codecarbon==2.2.3->autotrain-advanced)\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3->autotrain-advanced) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3->autotrain-advanced) (9.0.0)\n",
            "Collecting fuzzywuzzy (from codecarbon==2.2.3->autotrain-advanced)\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3->autotrain-advanced) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4->autotrain-advanced) (3.12.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4->autotrain-advanced) (6.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.21.4->autotrain-advanced) (2023.6.3)\n",
            "Collecting safetensors>=0.3.1 (from diffusers==0.21.4->autotrain-advanced)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from evaluate==0.3.0->autotrain-advanced)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0->autotrain-advanced) (3.4.1)\n",
            "Collecting multiprocess (from evaluate==0.3.0->autotrain-advanced)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0->autotrain-advanced) (2023.6.0)\n",
            "Collecting responses<0.19 (from evaluate==0.3.0->autotrain-advanced)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced) (4.2.2)\n",
            "Collecting fastapi (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading fastapi-0.104.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.5.0 (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading gradio_client-0.5.0-py3-none-any.whl (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced) (6.1.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading orjson-3.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.41.0->autotrain-advanced) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0->autotrain-advanced) (1.4.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0->autotrain-advanced) (4.8.0.76)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0->autotrain-advanced) (2.0.1+cu118)\n",
            "Collecting rapidfuzz==2.13.7 (from jiwer==3.0.2->autotrain-advanced)\n",
            "  Downloading rapidfuzz-2.13.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna==3.3.0->autotrain-advanced)\n",
            "  Downloading alembic-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.10.0 (from optuna==3.3.0->autotrain-advanced)\n",
            "  Downloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n",
            "Collecting colorlog (from optuna==3.3.0->autotrain-advanced)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna==3.3.0->autotrain-advanced) (2.0.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced) (2023.7.22)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.53->autotrain-advanced) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.0->autotrain-advanced) (3.2.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets[vision]~=2.14.0->autotrain-advanced) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets[vision]~=2.14.0->autotrain-advanced) (3.8.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->autotrain-advanced) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->autotrain-advanced) (2023.3.post1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (1.59.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (3.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (0.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (0.41.2)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers->autotrain-advanced)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tyro>=0.5.7 (from trl->autotrain-advanced)\n",
            "  Downloading tyro-0.5.10-py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/94.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Mako (from alembic>=1.5.0->optuna==3.3.0->autotrain-advanced)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced) (4.19.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced) (0.12.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[vision]~=2.14.0->autotrain-advanced) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->autotrain-advanced) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->autotrain-advanced) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->autotrain-advanced) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->autotrain-advanced) (1.3.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.41.0->autotrain-advanced) (3.1.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1->autotrain-advanced) (3.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1->autotrain-advanced) (2.31.5)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1->autotrain-advanced) (2023.9.26)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna==3.3.0->autotrain-advanced) (3.0.0)\n",
            "Collecting huggingface-hub>=0.16.4 (from autotrain-advanced)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->invisible-watermark==0.2.0->autotrain-advanced) (1.12)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->invisible-watermark==0.2.0->autotrain-advanced) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->invisible-watermark==0.2.0->autotrain-advanced) (3.27.7)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->invisible-watermark==0.2.0->autotrain-advanced) (17.0.2)\n",
            "Collecting docstring-parser>=0.14.1 (from tyro>=0.5.7->trl->autotrain-advanced)\n",
            "  Downloading docstring_parser-0.15-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.7->trl->autotrain-advanced) (13.6.0)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.7->trl->autotrain-advanced)\n",
            "  Downloading shtab-1.6.4-py3-none-any.whl (13 kB)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting types-python-dateutil>=2.8.10 (from arrow->codecarbon==2.2.3->autotrain-advanced)\n",
            "  Downloading types_python_dateutil-2.8.19.14-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio==3.41.0->autotrain-advanced) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions~=4.0 (from gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Collecting httpcore<0.19.0,>=0.18.0 (from httpx->gradio==3.41.0->autotrain-advanced)\n",
            "  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.41.0->autotrain-advanced) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.21.4->autotrain-advanced) (3.17.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio==3.41.0->autotrain-advanced) (1.1.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.41.0->autotrain-advanced) (0.10.6)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->autotrain-advanced) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->autotrain-advanced) (3.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.7->trl->autotrain-advanced) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.7->trl->autotrain-advanced) (2.16.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->invisible-watermark==0.2.0->autotrain-advanced) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.7->trl->autotrain-advanced) (0.1.2)\n",
            "Building wheels for collected packages: ipadic, sacremoses, ffmpy\n",
            "  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556703 sha256=1596d8e2c8c7c8bdfa643662167da991da2436e5f864d4664244773c9970d0bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/ea/e3/2f6e0860a327daba3b030853fce4483ed37468bbf1101c59c3\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=6afb615623f9f7c5b74cc9548616e43194f1db68a0d4be13cad3f544dea48ae7\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=fe6b8ae931b6dc66aa4c9a57875571befab767c216a3bb3110d4045fc6024f51\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built ipadic sacremoses ffmpy\n",
            "Installing collected packages: types-python-dateutil, sentencepiece, pydub, ipadic, fuzzywuzzy, ffmpy, bitsandbytes, werkzeug, websockets, typing-extensions, tqdm, shtab, semantic-version, safetensors, rapidfuzz, python-multipart, pynvml, protobuf, Pillow, packaging, orjson, Mako, loguru, joblib, h11, einops, docstring-parser, dill, colorlog, cmaes, aiofiles, xgboost, uvicorn, tiktoken, starlette, scikit-learn, sacremoses, responses, pydantic, multiprocess, jiwer, huggingface-hub, httpcore, arrow, tyro, tokenizers, httpx, fastapi, diffusers, codecarbon, alembic, transformers, optuna, gradio-client, datasets, gradio, evaluate, accelerate, trl, peft, invisible-watermark, autotrain-advanced\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.0.0\n",
            "    Uninstalling Werkzeug-3.0.0:\n",
            "      Successfully uninstalled Werkzeug-3.0.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.1\n",
            "    Uninstalling tqdm-4.66.1:\n",
            "      Successfully uninstalled tqdm-4.66.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.2\n",
            "    Uninstalling packaging-23.2:\n",
            "      Successfully uninstalled packaging-23.2\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.3.2\n",
            "    Uninstalling joblib-1.3.2:\n",
            "      Successfully uninstalled joblib-1.3.2\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 2.0.0\n",
            "    Uninstalling xgboost-2.0.0:\n",
            "      Successfully uninstalled xgboost-2.0.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "tensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.8.0 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.23.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.2.4 Pillow-10.0.0 accelerate-0.23.0 aiofiles-23.2.1 alembic-1.12.0 arrow-1.3.0 autotrain-advanced-0.6.37 bitsandbytes-0.41.1 cmaes-0.10.0 codecarbon-2.2.3 colorlog-6.7.0 datasets-2.14.5 diffusers-0.21.4 dill-0.3.7 docstring-parser-0.15 einops-0.6.1 evaluate-0.3.0 fastapi-0.104.0 ffmpy-0.3.1 fuzzywuzzy-0.18.0 gradio-3.41.0 gradio-client-0.5.0 h11-0.14.0 httpcore-0.18.0 httpx-0.25.0 huggingface-hub-0.17.3 invisible-watermark-0.2.0 ipadic-1.0.0 jiwer-3.0.2 joblib-1.3.1 loguru-0.7.0 multiprocess-0.70.15 optuna-3.3.0 orjson-3.9.9 packaging-23.1 peft-0.5.0 protobuf-4.23.4 pydantic-1.10.11 pydub-0.25.1 pynvml-11.5.0 python-multipart-0.0.6 rapidfuzz-2.13.7 responses-0.18.0 sacremoses-0.0.53 safetensors-0.4.0 scikit-learn-1.3.0 semantic-version-2.10.0 sentencepiece-0.1.99 shtab-1.6.4 starlette-0.27.0 tiktoken-0.5.1 tokenizers-0.14.1 tqdm-4.65.0 transformers-4.34.1 trl-0.7.2 types-python-dateutil-2.8.19.14 typing-extensions-4.8.0 tyro-0.5.10 uvicorn-0.23.2 websockets-11.0.3 werkzeug-2.3.6 xgboost-1.7.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> \u001b[1mINFO    Installing latest transformers@main\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest transformers\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest peft@main\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest peft\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest diffusers@main\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest diffusers\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest trl@main\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest trl\u001b[0m\n",
            "> \u001b[1mINFO    Installing latest xformers\u001b[0m\n",
            "> \u001b[1mINFO    Successfully installed latest xformers\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install autotrain-advanced\n",
        "!autotrain setup #--update-torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!autotrain llm --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF09QNgAzqkw",
        "outputId": "5a881fcc-459c-4371-c0e2-e550a062fc94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: autotrain <command> [<args>] llm [-h] [--train] [--deploy] [--inference]\n",
            "                                        [--data_path DATA_PATH] [--train_split TRAIN_SPLIT]\n",
            "                                        [--valid_split VALID_SPLIT] [--text_column TEXT_COLUMN]\n",
            "                                        [--rejected_text_column REJECTED_TEXT_COLUMN]\n",
            "                                        [--model MODEL] [--learning_rate LEARNING_RATE]\n",
            "                                        [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
            "                                        [--train_batch_size TRAIN_BATCH_SIZE]\n",
            "                                        [--warmup_ratio WARMUP_RATIO]\n",
            "                                        [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
            "                                        [--optimizer OPTIMIZER] [--scheduler SCHEDULER]\n",
            "                                        [--weight_decay WEIGHT_DECAY]\n",
            "                                        [--max_grad_norm MAX_GRAD_NORM] [--seed SEED]\n",
            "                                        [--add_eos_token] [--block_size BLOCK_SIZE] [--use_peft]\n",
            "                                        [--lora_r LORA_R] [--lora_alpha LORA_ALPHA]\n",
            "                                        [--lora_dropout LORA_DROPOUT]\n",
            "                                        [--logging_steps LOGGING_STEPS]\n",
            "                                        [--project_name PROJECT_NAME]\n",
            "                                        [--evaluation_strategy EVALUATION_STRATEGY]\n",
            "                                        [--save_total_limit SAVE_TOTAL_LIMIT]\n",
            "                                        [--save_strategy SAVE_STRATEGY] [--auto_find_batch_size]\n",
            "                                        [--fp16] [--push_to_hub] [--use_int8]\n",
            "                                        [--model_max_length MODEL_MAX_LENGTH] [--repo_id REPO_ID]\n",
            "                                        [--use_int4] [--trainer TRAINER]\n",
            "                                        [--target_modules TARGET_MODULES] [--merge_adapter]\n",
            "                                        [--token TOKEN] [--backend BACKEND] [--username USERNAME]\n",
            "                                        [--use_flash_attention_2]\n",
            "                                        [--disable_gradient_checkpointing]\n",
            "\n",
            "✨ Run AutoTrain LLM\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --train               Train the model\n",
            "  --deploy              Deploy the model\n",
            "  --inference           Run inference\n",
            "  --data_path DATA_PATH, --data-path DATA_PATH\n",
            "                        Train dataset to use\n",
            "  --train_split TRAIN_SPLIT, --train-split TRAIN_SPLIT\n",
            "                        Test dataset split to use\n",
            "  --valid_split VALID_SPLIT, --valid-split VALID_SPLIT\n",
            "                        Validation dataset split to use\n",
            "  --text_column TEXT_COLUMN, --text-column TEXT_COLUMN\n",
            "                        Text column to use\n",
            "  --rejected_text_column REJECTED_TEXT_COLUMN, --rejected-text-column REJECTED_TEXT_COLUMN\n",
            "                        Rejected text column to use\n",
            "  --model MODEL         Model to use\n",
            "  --learning_rate LEARNING_RATE, --lr LEARNING_RATE, --learning-rate LEARNING_RATE\n",
            "                        Learning rate to use\n",
            "  --num_train_epochs NUM_TRAIN_EPOCHS, --epochs NUM_TRAIN_EPOCHS\n",
            "                        Number of training epochs to use\n",
            "  --train_batch_size TRAIN_BATCH_SIZE, --train-batch-size TRAIN_BATCH_SIZE, --batch-size TRAIN_BATCH_SIZE\n",
            "                        Training batch size to use\n",
            "  --warmup_ratio WARMUP_RATIO, --warmup-ratio WARMUP_RATIO\n",
            "                        Warmup proportion to use\n",
            "  --gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS, --gradient-accumulation-steps GRADIENT_ACCUMULATION_STEPS, --gradient-accumulation GRADIENT_ACCUMULATION_STEPS\n",
            "                        Gradient accumulation steps to use\n",
            "  --optimizer OPTIMIZER\n",
            "                        Optimizer to use\n",
            "  --scheduler SCHEDULER\n",
            "                        Scheduler to use\n",
            "  --weight_decay WEIGHT_DECAY, --weight-decay WEIGHT_DECAY\n",
            "                        Weight decay to use\n",
            "  --max_grad_norm MAX_GRAD_NORM, --max-grad-norm MAX_GRAD_NORM\n",
            "                        Max gradient norm to use\n",
            "  --seed SEED           Seed to use\n",
            "  --add_eos_token, --add-eos-token\n",
            "                        Add EOS token to use\n",
            "  --block_size BLOCK_SIZE, --block-size BLOCK_SIZE\n",
            "                        Block size to use\n",
            "  --use_peft, --use-peft\n",
            "                        Use PEFT to use\n",
            "  --lora_r LORA_R, --lora-r LORA_R\n",
            "                        Lora r to use\n",
            "  --lora_alpha LORA_ALPHA, --lora-alpha LORA_ALPHA\n",
            "                        Lora alpha to use\n",
            "  --lora_dropout LORA_DROPOUT, --lora-dropout LORA_DROPOUT\n",
            "                        Lora dropout to use\n",
            "  --logging_steps LOGGING_STEPS, --logging-steps LOGGING_STEPS\n",
            "                        Logging steps to use\n",
            "  --project_name PROJECT_NAME, --project-name PROJECT_NAME\n",
            "                        Output directory\n",
            "  --evaluation_strategy EVALUATION_STRATEGY, --evaluation-strategy EVALUATION_STRATEGY\n",
            "                        Evaluation strategy to use\n",
            "  --save_total_limit SAVE_TOTAL_LIMIT, --save-total-limit SAVE_TOTAL_LIMIT\n",
            "                        Save total limit to use\n",
            "  --save_strategy SAVE_STRATEGY, --save-strategy SAVE_STRATEGY\n",
            "                        Save strategy to use\n",
            "  --auto_find_batch_size, --auto-find-batch-size\n",
            "                        Auto find batch size True/False\n",
            "  --fp16                FP16 True/False\n",
            "  --push_to_hub, --push-to-hub\n",
            "                        Push to hub True/False. In case you want to push the trained model to\n",
            "                        huggingface hub\n",
            "  --use_int8, --use-int8\n",
            "                        Use int8 True/False\n",
            "  --model_max_length MODEL_MAX_LENGTH, --max-len MODEL_MAX_LENGTH, --max-length MODEL_MAX_LENGTH\n",
            "                        Model max length to use\n",
            "  --repo_id REPO_ID, --repo-id REPO_ID\n",
            "                        Repo id for hugging face hub. Format is username/repo_name\n",
            "  --use_int4, --use-int4\n",
            "                        Use int4 True/False\n",
            "  --trainer TRAINER     Trainer type to use\n",
            "  --target_modules TARGET_MODULES, --target-modules TARGET_MODULES\n",
            "                        Target modules to use\n",
            "  --merge_adapter, --merge-adapter\n",
            "                        Use this flag to merge PEFT adapter with the model\n",
            "  --token TOKEN         Hugingface token to use\n",
            "  --backend BACKEND     Backend to use: default or spaces. Spaces backend requires push_to_hub and\n",
            "                        repo_id\n",
            "  --username USERNAME   Huggingface username to use\n",
            "  --use_flash_attention_2, --use-flash-attention-2, --use-fa2\n",
            "                        Use flash attention 2\n",
            "  --disable_gradient_checkpointing, --disable-gradient-checkpointing, --disable-gc\n",
            "                        Disable gradient checkpointing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!autotrain llm --train --project_name TuneTiger --model abhishek/llama-2-7b-hf-small-shards --data_path data/ --use_peft --use_int4 --learning_rate 2e-4 --train_batch_size 4 --num_train_epochs 1 --trainer sft --text_column text --push_to_hub --repo_id johan-jiremalm/TuneTiger5k --token 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"
      ],
      "metadata": {
        "id": "Tnd7qvI_9idN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5683629f-5a19-45f6-f6f2-ee21a71ba315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> \u001b[1mINFO    Running LLM\u001b[0m\n",
            "> \u001b[1mINFO    Params: Namespace(version=False, train=True, deploy=False, inference=False, data_path='data/', train_split='train', valid_split='val', text_column='text', rejected_text_column='rejected', model='abhishek/llama-2-7b-hf-small-shards', learning_rate=0.0002, num_train_epochs=1, train_batch_size=4, warmup_ratio=0.1, gradient_accumulation_steps=1, optimizer='adamw_torch', scheduler='linear', weight_decay=0.0, max_grad_norm=1.0, seed=42, add_eos_token=False, block_size=-1, use_peft=True, lora_r=16, lora_alpha=32, lora_dropout=0.05, logging_steps=-1, project_name='TuneTiger', evaluation_strategy='epoch', save_total_limit=1, save_strategy='epoch', auto_find_batch_size=False, fp16=False, push_to_hub=True, use_int8=False, model_max_length=1024, repo_id='johan-jiremalm/TuneTiger5k', use_int4=True, trainer='sft', target_modules=None, merge_adapter=False, token='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', backend='default', username=None, use_flash_attention_2=False, disable_gradient_checkpointing=False, func=<function run_llm_command_factory at 0x7b69d42ea5f0>)\u001b[0m\n",
            "> \u001b[1mINFO    loading dataset from csv\u001b[0m\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 8192.00it/s]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 763.02it/s]\n",
            "Generating train split: 5000 examples [00:00, 12757.57 examples/s]\n",
            "> \u001b[31m\u001b[1mERROR   train has failed due to an exception:\u001b[0m\n",
            "> \u001b[31m\u001b[1mERROR   Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autotrain/utils.py\", line 280, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autotrain/trainers/clm/__main__.py\", line 77, in train\n",
            "    valid_data = load_dataset(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/load.py\", line 2166, in load_dataset\n",
            "    ds = builder_instance.as_dataset(split=split, verification_mode=verification_mode, in_memory=keep_in_memory)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/builder.py\", line 1190, in as_dataset\n",
            "    datasets = map_nested(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/utils/py_utils.py\", line 456, in map_nested\n",
            "    return function(data_struct)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/builder.py\", line 1220, in _build_single_dataset\n",
            "    ds = self._as_dataset(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/builder.py\", line 1294, in _as_dataset\n",
            "    dataset_kwargs = ArrowReader(cache_dir, self.info).read(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/arrow_reader.py\", line 240, in read\n",
            "    files = self.get_file_instructions(name, instructions, split_infos)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/arrow_reader.py\", line 213, in get_file_instructions\n",
            "    file_instructions = make_file_instructions(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/arrow_reader.py\", line 130, in make_file_instructions\n",
            "    absolute_instructions = instruction.to_absolute(name2len)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/arrow_reader.py\", line 653, in to_absolute\n",
            "    return [_rel_to_abs_instr(rel_instr, name2len) for rel_instr in self._relative_instructions]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/arrow_reader.py\", line 653, in <listcomp>\n",
            "    return [_rel_to_abs_instr(rel_instr, name2len) for rel_instr in self._relative_instructions]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/datasets/arrow_reader.py\", line 465, in _rel_to_abs_instr\n",
            "    raise ValueError(f'Unknown split \"{split}\". Should be one of {list(name2len)}.')\n",
            "ValueError: Unknown split \"val\". Should be one of ['train'].\n",
            "\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}